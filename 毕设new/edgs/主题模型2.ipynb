{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.主题模型的sklearn实现--基于原始词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.057 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 5, \n",
      "Perplexity Score 463.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 10, \n",
      "Perplexity Score 438.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 15, \n",
      "Perplexity Score 424.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 20, \n",
      "Perplexity Score 415.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 25, \n",
      "Perplexity Score 413.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 30, \n",
      "Perplexity Score 411.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 35, \n",
      "Perplexity Score 422.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 40, \n",
      "Perplexity Score 432.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 45, \n",
      "Perplexity Score 446.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 50, \n",
      "Perplexity Score 446.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 55, \n",
      "Perplexity Score 444.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 60, \n",
      "Perplexity Score 441.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 65, \n",
      "Perplexity Score 460.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Topic: 70, \n",
      "Perplexity Score 459.074\n",
      "Best # of Topic:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.97772474e-05   3.97772474e-05   3.97772474e-05 ...,   3.97772474e-05\n",
      "    3.97772474e-05   3.97772474e-05]\n",
      " [  8.52514919e-05   8.52514919e-05   8.52514919e-05 ...,   8.52514919e-05\n",
      "    8.52514919e-05   8.52514919e-05]\n",
      " [  2.58197779e-05   2.58197779e-05   2.58197779e-05 ...,   2.58197779e-05\n",
      "    2.58197779e-05   2.58197779e-05]\n",
      " ..., \n",
      " [  5.44662309e-05   5.44662309e-05   5.44662309e-05 ...,   5.44662309e-05\n",
      "    5.44662309e-05   5.44662309e-05]\n",
      " [  5.43773790e-05   5.43773790e-05   5.43773790e-05 ...,   5.43773790e-05\n",
      "    5.43773790e-05   5.43773790e-05]\n",
      " [  9.71817298e-05   9.71817298e-05   9.71817298e-05 ...,   9.71817298e-05\n",
      "    9.71817298e-05   9.71817298e-05]]\n",
      "(30, 1282)\n",
      "[[ 0.30259287  0.2854735   0.27384483 ...,  8.756401    0.2485161\n",
      "   1.00354614]\n",
      " [ 2.52919537  0.22229977  0.99782709 ...,  0.21874174  5.57299541\n",
      "   0.22075323]\n",
      " [ 0.44158239  0.93020145  0.32754995 ...,  0.29830572  0.23460161\n",
      "   0.25376243]\n",
      " ..., \n",
      " [ 0.22521684  0.29319569  0.23758693 ...,  0.23921992  0.21794665\n",
      "   0.2303245 ]\n",
      " [ 0.19876764  0.2279882   0.23237538 ...,  0.22201933  0.1997928\n",
      "   0.24354207]\n",
      " [ 0.21951787  0.25533348  0.24346311 ...,  0.31306802  2.52963274\n",
      "   1.10380647]]\n",
      "Topic #0:\n",
      "教师 教育 教学 学生 实习 教师队伍 培养 培训 学习 研究\n",
      "Topic #1:\n",
      "项目 成本 研究 al 单位 施工 100 建筑 定稿 国家\n",
      "Topic #2:\n",
      "医疗 检查 医院 互认 数据 三级 患者 创业 影响 研究\n",
      "Topic #3:\n",
      "创业 大学生 金融 教育 农村 创新 发展 高校 模型 经济\n",
      "Topic #4:\n",
      "数据 数据挖掘 算法 分析 技术 研究 预测 聚类 模型 方法\n",
      "Topic #5:\n",
      "教师 教育 教学 金融 发展 教师队伍 实习 学生 培养 农村\n",
      "Topic #6:\n",
      "医疗 教学 企业 数据 专业 检查 学生 农业 发展 实践\n",
      "Topic #7:\n",
      "改革 农业 企业 综合 技术 客户 数据 工作 管理 农民\n",
      "Topic #8:\n",
      "患者 体验 服务 维度 评价 因素 就医 影响 分析 医院\n",
      "Topic #9:\n",
      "检查 分析 技术 数据 互认 医院 指标 工作 患者 医疗\n",
      "Topic #10:\n",
      "管理 施工 技术 工程 建筑 成本 质量 创新 企业 建筑工程\n",
      "Topic #11:\n",
      "影响 综合 医院 管理 建设 质量 利用 资源 空间 研究\n",
      "Topic #12:\n",
      "农户 农业 发展 网络 企业 农产品 模式 建设 生产 教学\n",
      "Topic #13:\n",
      "患者 学生 创业 教学 分析 创新 影响 专业 研究 实践\n",
      "Topic #14:\n",
      "检查 医疗 医院 互认 三级 患者 等级 制度 分析 医生\n",
      "Topic #15:\n",
      "施工 管理 服务 建筑 质量 改革 医疗 医院 公立医院 安装\n",
      "Topic #16:\n",
      "检查 医疗 医院 互认 数据 完善 患者 企业 质量 重复\n",
      "Topic #17:\n",
      "成本 施工 建筑 患者 大学生 项目 工程 工作 医疗 检查\n",
      "Topic #18:\n",
      "教学 学生 课程 专业 发展 改革 高校 实践 能力 理论\n",
      "Topic #19:\n",
      "实践 专业 教学 工程 学生 环节 企业 实验 自动化 教育\n",
      "Topic #20:\n",
      "检查 医疗 互认 医院 研究 算法 项目 方法 技术 患者\n",
      "Topic #21:\n",
      "创业 融资 模型 大学生 研究 预测 算法 创新 企业 分析\n",
      "Topic #22:\n",
      "改革 医院 检查 农业 综合 管理 发展 互认 医疗 技术\n",
      "Topic #23:\n",
      "特色 人才培养 人才 高校 发展 建设 学科 区域 教育 构建\n",
      "Topic #24:\n",
      "自动化 发展 设计 分析 行业 经济 提升 创业 竞争 借助\n",
      "Topic #25:\n",
      "发展 高校 人才培养 服务 人才 创新 金融 影响 国际 提升\n",
      "Topic #26:\n",
      "模型 样本 方法 算法 质量 技术 研究 数据 医疗机构 监测\n",
      "Topic #27:\n",
      "建筑 医疗 互认 施工 结构 检查 成本 设计 工程 保证\n",
      "Topic #28:\n",
      "农业 发展 农村 金融 产品 模型 建设 经营 收入 服务\n",
      "Topic #29:\n",
      "农业 发展 农户 企业 农产品 网络 产品 模式 农村 经营\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#先弄出文档词频矩阵，然后进行相应的模型训练\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "rawfile=[]#空格分隔开的文本\n",
    "for i in range(len(df2)):\n",
    "    rawfile.append(' '.join(df2['fenci'][i]))\n",
    "#print(rawfile) \n",
    "#rawfile listoflist ,每一项为用空格连接的一篇文档\n",
    "countvec = CountVectorizer(min_df = 0.1)#最小词频\n",
    "X = countvec.fit_transform(rawfile)#稀疏矩阵\n",
    "\n",
    "#基于词频矩阵X计算TF-IDF值\n",
    "#---------------------------------\n",
    "#设定LDA模型\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics = range(5, 75, 5)\n",
    "perplexityLst = [1.0]*len(n_topics)\n",
    "#训练LDA并打印训练时间\n",
    "lda_models = []\n",
    "for idx, n_topic in enumerate(n_topics):\n",
    "    lda = LatentDirichletAllocation(n_topics=n_topic,max_iter=20,learning_method='batch',evaluate_every=200,verbose=0)\n",
    "  \n",
    "    lda.fit(X)\n",
    "    perplexityLst[idx] = lda.perplexity(X)\n",
    "    lda_models.append(lda)\n",
    "    print(\"# of Topic: %d, \" % n_topics[idx])\n",
    "    print(\"Perplexity Score %0.3f\" % perplexityLst[idx])\n",
    "#打印最佳模型\n",
    "best_index = perplexityLst.index(min(perplexityLst))\n",
    "best_n_topic = n_topics[best_index]\n",
    "best_model = lda_models[best_index]\n",
    "print(\"Best # of Topic: \", best_n_topic)\n",
    "\n",
    "\n",
    "#设定LDA模型\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics=best_n_topic#提取主题个数\n",
    "ldamodel = LatentDirichletAllocation(n_components= n_topics)\n",
    "#拟合LDA模型\n",
    "docres = ldamodel.fit_transform(X)\n",
    "#拟合后的模型实质\n",
    "print(docres)\n",
    "print(ldamodel.components_.shape)#(10,705)\n",
    "print(ldamodel.components_)#前两条，每个主题中每个词条出现的概率\n",
    "\n",
    "#打印主题词\n",
    "def print_top_words(model,feature_names,n_top_words):\n",
    "    for topic_idx,topic in enumerate(model.components_):\n",
    "        print('Topic #%d:'% topic_idx)\n",
    "        print(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "n_top_words = 10\n",
    "tf_feature_names = countvec.get_feature_names()\n",
    "print_top_words(ldamodel, tf_feature_names, n_top_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.主题模型的sklearn实现--基于tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅', '_一带一路_背景下_国际投资_课_省略_路径探析_以广西民族师范学院为例_郑国富', '三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏', '不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹', '乡村振兴战略下环巢湖休闲农业发展研究_沈东生', '二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁', '关于建筑工程管理的影响因素分析与对策探讨_王君霞_战丙利', '关于彰武县做好互换并地后续工作的建议_张凤华', '关于深化河北省农业水价综合改革的对策建议_马素英', '农村非正规金融发展与农村多维贫困_基于面板门槛模型的研究_吴君娴_黄永兴', '医师多点执业对医院人力资源管理的影响_张妍_李吉', '协同创新优化现代高效农业组织结构_王瑜', '县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', '双创背景下大学生农业创业融资问题探析_王涛_白林_齐骥霆', '吉林省农村金融发展状况及对策研究_孙铁柱', '国家重点研发计划_畜禽_专项立项特征研究_姜玮', '地方高校工科专业课程教学模式改革_省略_临沂大学_大气污染控制工程_为例_马宏卿', '基于大数据的商业智能在电商数据分析中的应用_钱丹丹', '基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', '基于数据挖掘的电影票房分析_席稼玮', '基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', '工程教育专业认证下自动化专业实践教学体系的构建_黄宜庆_陆华才', '工程造价指数与工程造价动态管理刍议_孙静', '广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_', '应用型高校金融学课程教学改革研究_邓旭霞', '建筑工程施工管理及创新技术的应用研究_侯帅', '建筑工程施工管理的进度管理与控制_吕萌', '建筑结构设计中的抗震结构设计理念_马玉洁', '建筑门窗用硅烷改性聚醚胶的性能与应用研究_杨苏邯_陈洋庆_陈建军_龙飞_蒋金博_', '我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', '数据挖掘技术在语音识别中的应用_许元洪_郭琼', '数据挖掘技术在风力发电中的应用综述_曾文珺', '智能建筑电气安装工程质量控制要点解析_张凯_张振玉', '河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', '浅析建筑道桥的施工成本把控现状及解决对策_温秀红', '浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', '浅谈洛阳地区窑居建筑通风采光设计策略_周亚豪_赵余光_梁文涛_陈奕甫_杨梦辉', '浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明', '电力文本数据挖掘现状及挑战_王慧芳', '绥化市农业电子商务发展模式研究_余娟_赵艳_孙晓_李冰_张云晖', '耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', '芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', '药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸', '藜麦营养功能与开发利用进展_王启明', '解析装配式建筑工程施工过程中BIM技术的应用_刘志文', '辽宁省特色人才培养模式研究_郭晓林_徐靓', '遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', '面向调度运行分析的电网数据分析与挖掘_张英华', '高校大学生就业指导中的思想政治教育研究_张梦君', '高校油画专业课堂教学改革探究_舒文鑫']\n",
      "# of Topic: 1, \n",
      "Perplexity Score 1730.609\n",
      "# of Topic: 2, \n",
      "Perplexity Score 3060.611\n",
      "# of Topic: 3, \n",
      "Perplexity Score 4304.003\n",
      "# of Topic: 4, \n",
      "Perplexity Score 7080.718\n",
      "# of Topic: 5, \n",
      "Perplexity Score 8168.398\n",
      "# of Topic: 6, \n",
      "Perplexity Score 11963.651\n",
      "# of Topic: 7, \n",
      "Perplexity Score 16123.037\n",
      "# of Topic: 8, \n",
      "Perplexity Score 24484.086\n",
      "# of Topic: 9, \n",
      "Perplexity Score 28199.329\n",
      "# of Topic: 10, \n",
      "Perplexity Score 37139.618\n",
      "# of Topic: 11, \n",
      "Perplexity Score 44285.888\n",
      "# of Topic: 12, \n",
      "Perplexity Score 66361.943\n",
      "# of Topic: 13, \n",
      "Perplexity Score 87808.347\n",
      "# of Topic: 14, \n",
      "Perplexity Score 161442.454\n",
      "# of Topic: 15, \n",
      "Perplexity Score 134840.901\n",
      "# of Topic: 16, \n",
      "Perplexity Score 272013.516\n",
      "# of Topic: 17, \n",
      "Perplexity Score 379305.088\n",
      "# of Topic: 18, \n",
      "Perplexity Score 222480.137\n",
      "# of Topic: 19, \n",
      "Perplexity Score 448707.561\n",
      "# of Topic: 20, \n",
      "Perplexity Score 367841.285\n",
      "# of Topic: 21, \n",
      "Perplexity Score 524384.511\n",
      "# of Topic: 22, \n",
      "Perplexity Score 548022.570\n",
      "# of Topic: 23, \n",
      "Perplexity Score 657162.558\n",
      "# of Topic: 24, \n",
      "Perplexity Score 792403.464\n",
      "# of Topic: 25, \n",
      "Perplexity Score 1357638.815\n",
      "# of Topic: 26, \n",
      "Perplexity Score 1501515.924\n",
      "# of Topic: 27, \n",
      "Perplexity Score 1472169.829\n",
      "# of Topic: 28, \n",
      "Perplexity Score 1707460.230\n",
      "# of Topic: 29, \n",
      "Perplexity Score 2172239.806\n",
      "Best # of Topic:  1\n",
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=200, learning_decay=0.7,\n",
      "             learning_method='batch', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=20, mean_change_tol=0.001,\n",
      "             n_components=1, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
      "             random_state=None, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n",
      "(1, 1280)\n",
      "[[ 1.25154212  1.37481709  1.11255326 ...,  1.25554024  1.17400813\n",
      "   1.26849544]]\n",
      "Topic #0:\n",
      "农业 医院 医疗 建筑 教学 施工 发展 检查 数据 管理\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#先弄出文档词频矩阵，然后进行相应的模型训练\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "rawfile=[]#空格分隔开的文本\n",
    "for i in range(len(df2)):\n",
    "    rawfile.append(' '.join(df2['fenci'][i]))\n",
    "#print(rawfile) \n",
    "#rawfile listoflist ,每一项为用空格连接的一篇文档\n",
    "countvec = CountVectorizer(min_df = 5)#最小词频\n",
    "X = countvec.fit_transform(rawfile)#稀疏矩阵\n",
    "\n",
    "#基于词频矩阵X计算TF-IDF值  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()  \n",
    "tfidf = transformer.fit_transform(X)  \n",
    "tfidf\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "#设定LDA模型\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics = range(1, 30, 1)\n",
    "perplexityLst = [1.0]*len(n_topics)\n",
    "#训练LDA并打印训练时间\n",
    "lda_models = []\n",
    "for idx, n_topic in enumerate(n_topics):\n",
    "    lda = LatentDirichletAllocation(n_components=n_topic,max_iter=20,learning_method='batch',evaluate_every=200,verbose=0)  #设定LDA模型\n",
    "    lda.fit(tfidf)#拟合LDA模型\n",
    "    perplexityLst[idx] = lda.perplexity(tfidf)\n",
    "    lda_models.append(lda)\n",
    "    print(\"# of Topic: %d, \" % n_topics[idx])\n",
    "    print(\"Perplexity Score %0.3f\" % perplexityLst[idx])\n",
    "#打印最佳模型\n",
    "best_index = perplexityLst.index(min(perplexityLst))\n",
    "best_n_topic = n_topics[best_index]\n",
    "best_model = lda_models[best_index]\n",
    "print(\"Best # of Topic: \", best_n_topic)\n",
    "\n",
    "\n",
    "#设定LDA模型\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics=best_n_topic#提取主题个数\n",
    "ldamodel = LatentDirichletAllocation(n_components= n_topics,max_iter=20,learning_method='batch',evaluate_every=200,verbose=0)\n",
    "#拟合LDA模型\n",
    "docres = ldamodel.fit(tfidf)\n",
    "#拟合后的模型实质\n",
    "print(docres)\n",
    "print(ldamodel.components_.shape)#(10,705)\n",
    "print(ldamodel.components_)#前两条，每个主题中每个词条出现的概率\n",
    "\n",
    "#打印主题词\n",
    "def print_top_words(model,feature_names,n_top_words):\n",
    "    for topic_idx,topic in enumerate(model.components_):\n",
    "        print('Topic #%d:'% topic_idx)\n",
    "        print(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "n_top_words = 10\n",
    "tf_feature_names = countvec.get_feature_names()\n",
    "print_top_words(ldamodel, tf_feature_names, n_top_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.主题模型的gensim实现---基于原始词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅', '_一带一路_背景下_国际投资_课_省略_路径探析_以广西民族师范学院为例_郑国富', '三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏', '不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹', '乡村振兴战略下环巢湖休闲农业发展研究_沈东生', '二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁', '关于建筑工程管理的影响因素分析与对策探讨_王君霞_战丙利', '关于彰武县做好互换并地后续工作的建议_张凤华', '关于深化河北省农业水价综合改革的对策建议_马素英', '农村非正规金融发展与农村多维贫困_基于面板门槛模型的研究_吴君娴_黄永兴', '医师多点执业对医院人力资源管理的影响_张妍_李吉', '协同创新优化现代高效农业组织结构_王瑜', '县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', '双创背景下大学生农业创业融资问题探析_王涛_白林_齐骥霆', '吉林省农村金融发展状况及对策研究_孙铁柱', '国家重点研发计划_畜禽_专项立项特征研究_姜玮', '地方高校工科专业课程教学模式改革_省略_临沂大学_大气污染控制工程_为例_马宏卿', '基于大数据的商业智能在电商数据分析中的应用_钱丹丹', '基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', '基于数据挖掘的电影票房分析_席稼玮', '基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', '工程教育专业认证下自动化专业实践教学体系的构建_黄宜庆_陆华才', '工程造价指数与工程造价动态管理刍议_孙静', '广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_', '应用型高校金融学课程教学改革研究_邓旭霞', '建筑工程施工管理及创新技术的应用研究_侯帅', '建筑工程施工管理的进度管理与控制_吕萌', '建筑结构设计中的抗震结构设计理念_马玉洁', '建筑门窗用硅烷改性聚醚胶的性能与应用研究_杨苏邯_陈洋庆_陈建军_龙飞_蒋金博_', '我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', '数据挖掘技术在语音识别中的应用_许元洪_郭琼', '数据挖掘技术在风力发电中的应用综述_曾文珺', '智能建筑电气安装工程质量控制要点解析_张凯_张振玉', '河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', '浅析建筑道桥的施工成本把控现状及解决对策_温秀红', '浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', '浅谈洛阳地区窑居建筑通风采光设计策略_周亚豪_赵余光_梁文涛_陈奕甫_杨梦辉', '浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明', '电力文本数据挖掘现状及挑战_王慧芳', '绥化市农业电子商务发展模式研究_余娟_赵艳_孙晓_李冰_张云晖', '耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', '芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', '药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸', '藜麦营养功能与开发利用进展_王启明', '解析装配式建筑工程施工过程中BIM技术的应用_刘志文', '辽宁省特色人才培养模式研究_郭晓林_徐靓', '遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', '面向调度运行分析的电网数据分析与挖掘_张英华', '高校大学生就业指导中的思想政治教育研究_张梦君', '高校油画专业课堂教学改革探究_舒文鑫']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.72 s\n",
      "[(7, 0.99948984)]\n",
      "[(5, 0.99874002)]\n",
      "[(3, 0.38028145), (12, 0.61918026)]\n",
      "[(3, 0.60159111), (10, 0.39780325)]\n",
      "[(11, 0.99938947)]\n",
      "[(3, 0.99941468)]\n",
      "[(5, 0.33153448), (8, 0.56558716), (11, 0.055836685), (19, 0.045757547)]\n",
      "[(11, 0.04908929), (17, 0.94950008)]\n",
      "[(17, 0.99954176)]\n",
      "[(11, 0.99958807)]\n",
      "[(8, 0.99924904)]\n",
      "[(11, 0.16527814), (15, 0.83317548)]\n",
      "[(8, 0.99960202)]\n",
      "[(5, 0.9615432), (11, 0.036667552)]\n",
      "[(11, 0.030997824), (16, 0.96765488)]\n",
      "[(18, 0.99937087)]\n",
      "[(5, 0.7110883), (10, 0.28838477)]\n",
      "[(1, 0.99931759)]\n",
      "[(19, 0.99918389)]\n",
      "[(14, 0.99723685)]\n",
      "[(19, 0.99970996)]\n",
      "[(4, 0.58425057), (5, 0.40395463), (15, 0.011006317)]\n",
      "[(4, 0.8168816), (11, 0.18175685)]\n",
      "[(13, 0.99965703)]\n",
      "[(5, 0.99942636)]\n",
      "[(5, 0.10778086), (8, 0.40959343), (11, 0.17592697), (19, 0.2961106)]\n",
      "[(8, 0.99857783)]\n",
      "[(19, 0.99851328)]\n",
      "[(12, 0.99938595)]\n",
      "[(3, 0.32258689), (13, 0.6766873)]\n",
      "[(15, 0.99863702)]\n",
      "[(4, 0.074221618), (18, 0.92550272)]\n",
      "[(8, 0.99862117)]\n",
      "[(5, 0.8639431), (7, 0.1356938)]\n",
      "[(8, 0.03978119), (11, 0.95938474)]\n",
      "[(0, 0.99836487)]\n",
      "[(16, 0.99916887)]\n",
      "[(12, 0.73635817), (19, 0.26322532)]\n",
      "[(15, 0.99964464)]\n",
      "[(11, 0.99948984)]\n",
      "[(7, 0.99874443)]\n",
      "[(5, 0.99933428)]\n",
      "[(6, 0.99926132)]\n",
      "[(10, 0.99976331)]\n",
      "[(8, 0.088115275), (19, 0.91054147)]\n",
      "[(5, 0.3710168), (15, 0.62747061)]\n",
      "[(1, 0.99902362)]\n",
      "[(1, 0.99907684)]\n",
      "[(5, 0.99887305)]\n",
      "[(5, 0.99815172)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 0.99948984)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文档预处理\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "filelist=[]\n",
    "for i in range(len(df2)):\n",
    "    filelist.append(df2['fenci'][i])\n",
    "#生成文档对应的字典和bow稀疏矩阵\n",
    "from gensim import corpora, models  \n",
    "\n",
    "dictionary = corpora.Dictionary(filelist)  \n",
    "corpus = [dictionary.doc2bow(text) for text in filelist] # 仍为list in list  \n",
    "\n",
    "\n",
    "num_topics = range(5, 75, 5)\n",
    "perplexityLst = [1.0]*len(num_topics)\n",
    "#训练LDA并打印训练时间\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "#拟合LDA模型\n",
    "\n",
    "# 列出所消耗的时间备查\n",
    "%time ldamodel = LdaModel(corpus, id2word = dictionary, num_topics = 20, passes = 10) \n",
    "#列出最重要的若干个主题\n",
    "ldamodel.print_topics(num_topics = 20,num_words = 10)\n",
    "\n",
    "\n",
    "#计算各语料的LDA模型值\n",
    "corpus_lda = ldamodel[corpus] # 此处应当使用和模型训练时相同类型的矩阵\n",
    "for doc in corpus_lda:\n",
    "    print(doc)\n",
    "ldamodel.get_topics()#list of list 每个主题中每个词所对应的一个概率矩阵\n",
    "\n",
    "# 检索和文本内容最接近的主题\n",
    " # 检索和0.txt最接近的主题\n",
    "query_bow = dictionary.doc2bow(df2['fenci'][0]) # 频数向量\n",
    "ldamodel.get_document_topics(query_bow) # 需要输入和文档对应的bow向量\n",
    "# 检索和文本内容最接近的主题\n",
    "\n",
    "ldamodel[query_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.主题模型的gensim实现--基于tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '4', '5', '6', '7', '8', '9']\n",
      "Wall time: 4.36 s\n",
      "[(10, 0.91385609)]\n",
      "[(10, 0.91385603)]\n",
      "[(6, 0.89495426)]\n",
      "[(0, 0.86213541), (10, 0.073513709)]\n",
      "[(5, 0.92821234)]\n",
      "[(7, 0.77676058), (10, 0.12868217)]\n",
      "[(2, 0.90814662)]\n",
      "[(2, 0.87616169)]\n",
      "[(4, 0.90784776)]\n",
      "[(11, 0.95246303)]\n",
      "[(6, 0.84513742), (10, 0.093349896)]\n",
      "[(10, 0.90029097)]\n",
      "[(10, 0.95400578)]\n",
      "[(5, 0.91536862)]\n",
      "[(9, 0.91491938)]\n",
      "[(1, 0.87114596)]\n",
      "[(8, 0.81713909), (10, 0.11409672)]\n",
      "[(10, 0.87475252)]\n",
      "[(14, 0.90469038)]\n",
      "[(2, 0.91045159), (10, 0.025985157)]\n",
      "[(0, 0.73818505), (10, 0.19431612)]\n",
      "[(1, 0.93858361)]\n",
      "[(6, 0.91869694)]\n",
      "[(14, 0.89184088)]\n",
      "[(13, 0.94317943)]\n",
      "[(8, 0.91134542)]\n",
      "[(3, 0.73237473), (10, 0.19228522)]\n",
      "[(12, 0.93265635)]\n",
      "[(13, 0.94652838)]\n",
      "[(10, 0.94208616)]\n",
      "[(6, 0.91629094)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 0.91385609)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文档预处理\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "filelist=[]\n",
    "for i in range(len(df2)):\n",
    "    filelist.append(df2['fenci'][i])\n",
    "#生成文档对应的字典和bow稀疏矩阵\n",
    "from gensim import corpora, models  \n",
    "\n",
    "dictionary = corpora.Dictionary(filelist)  \n",
    "corpus = [dictionary.doc2bow(text) for text in filelist] # 仍为list in list  \n",
    "\n",
    "tfidf_model = models.TfidfModel(corpus) # 建立TF-IDF模型  \n",
    "corpus_tfidf = tfidf_model[corpus] # 对所需文档计算TF-IDF结果\n",
    "corpus_tfidf\n",
    "\n",
    "#训练LDA并打印训练时间\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "#拟合LDA模型\n",
    "\n",
    "# 列出所消耗的时间备查\n",
    "%time ldamodel = LdaModel(corpus_tfidf, id2word = dictionary, num_topics = 15, passes = 10) \n",
    "#列出最重要的若干个主题\n",
    "ldamodel.print_topics(num_topics = 15,num_words = 10)\n",
    "\n",
    "\n",
    "#计算各语料的LDA模型值\n",
    "corpus_lda = ldamodel[corpus_tfidf] # 此处应当使用和模型训练时相同类型的矩阵\n",
    "for doc in corpus_lda:\n",
    "    print(doc)\n",
    "ldamodel.get_topics()#list of list 每个主题中每个词所对应的一个概率矩阵\n",
    "\n",
    "# 检索和文本内容最接近的主题\n",
    " # 检索和0.txt最接近的主题\n",
    "query_bow = dictionary.doc2bow(df2['fenci'][0]) # 频数向量\n",
    "query_tfidf = tfidf_model[query_bow]\n",
    "ldamodel.get_document_topics(query_tfidf) # 需要输入和文档对应的bow向量\n",
    "# 检索和文本内容最接近的主题\n",
    "\n",
    "ldamodel[query_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
