{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅', '_一带一路_背景下_国际投资_课_省略_路径探析_以广西民族师范学院为例_郑国富', '三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏', '不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹', '乡村振兴战略下环巢湖休闲农业发展研究_沈东生', '二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁', '关于建筑工程管理的影响因素分析与对策探讨_王君霞_战丙利', '关于彰武县做好互换并地后续工作的建议_张凤华', '关于深化河北省农业水价综合改革的对策建议_马素英', '农村非正规金融发展与农村多维贫困_基于面板门槛模型的研究_吴君娴_黄永兴', '医师多点执业对医院人力资源管理的影响_张妍_李吉', '协同创新优化现代高效农业组织结构_王瑜', '县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', '双创背景下大学生农业创业融资问题探析_王涛_白林_齐骥霆', '吉林省农村金融发展状况及对策研究_孙铁柱', '国家重点研发计划_畜禽_专项立项特征研究_姜玮', '地方高校工科专业课程教学模式改革_省略_临沂大学_大气污染控制工程_为例_马宏卿', '基于大数据的商业智能在电商数据分析中的应用_钱丹丹', '基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', '基于数据挖掘的电影票房分析_席稼玮', '基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', '工程教育专业认证下自动化专业实践教学体系的构建_黄宜庆_陆华才', '工程造价指数与工程造价动态管理刍议_孙静', '广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_', '应用型高校金融学课程教学改革研究_邓旭霞', '建筑工程施工管理及创新技术的应用研究_侯帅', '建筑工程施工管理的进度管理与控制_吕萌', '建筑结构设计中的抗震结构设计理念_马玉洁', '建筑门窗用硅烷改性聚醚胶的性能与应用研究_杨苏邯_陈洋庆_陈建军_龙飞_蒋金博_', '我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', '数据挖掘技术在语音识别中的应用_许元洪_郭琼', '数据挖掘技术在风力发电中的应用综述_曾文珺', '智能建筑电气安装工程质量控制要点解析_张凯_张振玉', '河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', '浅析建筑道桥的施工成本把控现状及解决对策_温秀红', '浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', '浅谈洛阳地区窑居建筑通风采光设计策略_周亚豪_赵余光_梁文涛_陈奕甫_杨梦辉', '浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明', '电力文本数据挖掘现状及挑战_王慧芳', '绥化市农业电子商务发展模式研究_余娟_赵艳_孙晓_李冰_张云晖', '耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', '芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', '药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸', '藜麦营养功能与开发利用进展_王启明', '解析装配式建筑工程施工过程中BIM技术的应用_刘志文', '辽宁省特色人才培养模式研究_郭晓林_徐靓', '遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', '面向调度运行分析的电网数据分析与挖掘_张英华', '高校大学生就业指导中的思想政治教育研究_张梦君', '高校油画专业课堂教学改革探究_舒文鑫']\n",
      "[2.9933264151908165, 0, 2.6808128566723775, 2.5359617218714727, 0, 2.003008420025968, 0, 0, 0, 0, 2.3083958618075644, 0, 1.9882564505302798, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.7823303533912087, 0, 0, 0, 0, 0, 2.752951326447808, 0, 0, 0, 0, 0, 0, 0, 2.3042484227907583, 0, 0, 0, 0, 2.121835077060319, 0, 0, 0, 2.409451893551827, 0, 0, 0]\n",
      "[(0, 2.9933264151908165), (23, 2.7823303533912087), (29, 2.752951326447808), (2, 2.6808128566723775), (3, 2.5359617218714727), (46, 2.409451893551827), (10, 2.3083958618075644), (37, 2.3042484227907583), (42, 2.121835077060319), (5, 2.003008420025968), (12, 1.9882564505302798), (1, 0), (4, 0), (6, 0), (7, 0), (8, 0), (9, 0), (11, 0), (13, 0), (14, 0), (15, 0), (16, 0), (17, 0), (18, 0), (19, 0), (20, 0), (21, 0), (22, 0), (24, 0), (25, 0), (26, 0), (27, 0), (28, 0), (30, 0), (31, 0), (32, 0), (33, 0), (34, 0), (35, 0), (36, 0), (38, 0), (39, 0), (40, 0), (41, 0), (43, 0), (44, 0), (45, 0), (47, 0), (48, 0), (49, 0)]\n",
      "2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅:2.9933264151908165\n",
      "广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_:2.7823303533912087\n",
      "我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚:2.752951326447808\n",
      "三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏:2.6808128566723775\n",
      "不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹:2.5359617218714727\n",
      "遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌:2.409451893551827\n",
      "医师多点执业对医院人力资源管理的影响_张妍_李吉:2.3083958618075644\n",
      "浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明:2.3042484227907583\n",
      "药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸:2.121835077060319\n",
      "二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁:2.003008420025968\n",
      "县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应:1.9882564505302798\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class BM25(object):\n",
    "\n",
    "    def __init__(self, docs):\n",
    "        self.D = len(docs)\n",
    "        self.avgdl = sum([len(doc)+0.0 for doc in docs]) / self.D\n",
    "        self.docs = docs\n",
    "        self.f = []  # 列表的每一个元素是一个dict，dict存储着一个文档中每个词的出现次数\n",
    "        self.df = {} # 存储每个词及出现了该词的文档数量\n",
    "        self.idf = {} # 存储每个词的idf值\n",
    "        self.k1 = 1.5\n",
    "        self.b = 0.75\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        for doc in self.docs:\n",
    "            tmp = {}\n",
    "            for word in doc:\n",
    "                tmp[word] = tmp.get(word, 0) + 1  # 存储每个文档中每个词的出现次数\n",
    "            self.f.append(tmp)\n",
    "            for k in tmp.keys():\n",
    "                self.df[k] = self.df.get(k, 0) + 1\n",
    "        for k, v in self.df.items():\n",
    "            self.idf[k] = math.log(self.D-v+0.5)-math.log(v+0.5)\n",
    "\n",
    "    def sim(self, doc, index):\n",
    "        score = 0\n",
    "        for word in doc:\n",
    "            if word not in self.f[index]:\n",
    "                continue\n",
    "            d = len(self.docs[index])\n",
    "            score += (self.idf[word]*self.f[index][word]*(self.k1+1)\n",
    "                      / (self.f[index][word]+self.k1*(1-self.b+self.b*d\n",
    "                                                      / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def simall(self, doc):\n",
    "        scores = []\n",
    "        for index in range(self.D):\n",
    "            score = self.sim(doc, index)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from MyDataFrame import MyDataFrame\n",
    "    mdf = MyDataFrame()\n",
    "    df = mdf.new_DataFrame()\n",
    "    df2 = mdf.m_cut(df)\n",
    "    filelist=[]\n",
    "    for i in range(len(df2)):\n",
    "        filelist.append(df2['fenci'][i])\n",
    "    \n",
    "    \n",
    "    s = BM25(filelist)\n",
    "    #print(s.f)\n",
    "    #print(s.idf)\n",
    "    #print(s.simall(['医疗机构', '数据挖掘', '领域', '一带一路', '领域']))\n",
    "    #print(type(s.simall(['医疗机构', '数据挖掘', '领域', '一带一路', '领域'])))\n",
    "    scores = s.simall(['医疗机构'])\n",
    "    #scores.sort()\n",
    "    print(scores)\n",
    "    simfile_list = []\n",
    "    for i in range(len(scores)):\n",
    "        simfile_list.append((i,scores[i]))\n",
    "        \n",
    "    import operator\n",
    "    \n",
    "    simfile_list.sort(key=operator.itemgetter(1),reverse=True)\n",
    "    print(simfile_list)\n",
    "    \n",
    "    for i in range(len(simfile_list)):\n",
    "        a,b = simfile_list[i]\n",
    "        if b != 0:\n",
    "            print(df.filename[a] +\":\"+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "[-1.505838115009245, 0, -1.4660867650816511, -0.3369529696903013, 1.3119425371801974, -0.22601855322944178, 0, -1.7033107957403357, -0.6985855666948058, -0.9015508929774181, 0, -1.7182585023435717, 0.49094762225912963, -1.1757365859809823, 0, -2.1671752565925098, -0.0039618644282790605, 3.8823105648163745, 3.916777743587672, 1.5415259841786113, 0.8931336505414746, -1.4784781068102386, 0.969745738492992, -1.9964543553286003, 0.8669451233115186, -2.424178139276573, -1.600029274309525, 3.932228906336272, -1.4945796145692782, 2.218956643306386, 1.8214074459421494, 4.490857260874413, 0, 0.2576320203286757, 0, 11.410737768074416, -0.18326955745390738, -0.9771814641971845, 8.309548356736132, -1.645348437585522, 0.162285284084546, 0.5269008031710858, -1.9393260399807017, -1.5000211733214317, -2.426339856085014, -0.3225656662966298, 5.242350072548432, 4.928665646933318, 0, -1.8361622973596767]\n",
      "[(35, 11.410737768074416), (38, 8.309548356736132), (46, 5.242350072548432), (47, 4.928665646933318), (31, 4.490857260874413), (27, 3.932228906336272), (18, 3.916777743587672), (17, 3.8823105648163745), (29, 2.218956643306386), (30, 1.8214074459421494), (19, 1.5415259841786113), (4, 1.3119425371801974), (22, 0.969745738492992), (20, 0.8931336505414746), (24, 0.8669451233115186), (41, 0.5269008031710858), (12, 0.49094762225912963), (33, 0.2576320203286757), (40, 0.162285284084546), (1, 0), (6, 0), (10, 0), (14, 0), (32, 0), (34, 0), (48, 0), (16, -0.0039618644282790605), (36, -0.18326955745390738), (5, -0.22601855322944178), (45, -0.3225656662966298), (3, -0.3369529696903013), (8, -0.6985855666948058), (9, -0.9015508929774181), (37, -0.9771814641971845), (13, -1.1757365859809823), (2, -1.4660867650816511), (21, -1.4784781068102386), (28, -1.4945796145692782), (43, -1.5000211733214317), (0, -1.505838115009245), (26, -1.600029274309525), (39, -1.645348437585522), (7, -1.7033107957403357), (11, -1.7182585023435717), (49, -1.8361622973596767), (42, -1.9393260399807017), (23, -1.9964543553286003), (15, -2.1671752565925098), (25, -2.424178139276573), (44, -2.426339856085014)]\n",
      "浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗:11.410737768074416\n",
      "35\n",
      "电力文本数据挖掘现状及挑战_王慧芳:8.309548356736132\n",
      "38\n",
      "遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌:5.242350072548432\n",
      "46\n",
      "面向调度运行分析的电网数据分析与挖掘_张英华:4.928665646933318\n",
      "47\n",
      "数据挖掘技术在风力发电中的应用综述_曾文珺:4.490857260874413\n",
      "31\n",
      "建筑结构设计中的抗震结构设计理念_马玉洁:3.932228906336272\n",
      "27\n",
      "基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐:3.916777743587672\n",
      "18\n",
      "基于大数据的商业智能在电商数据分析中的应用_钱丹丹:3.8823105648163745\n",
      "17\n",
      "我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚:2.218956643306386\n",
      "29\n",
      "数据挖掘技术在语音识别中的应用_许元洪_郭琼:1.8214074459421494\n",
      "30\n",
      "基于数据挖掘的电影票房分析_席稼玮:1.5415259841786113\n",
      "19\n",
      "乡村振兴战略下环巢湖休闲农业发展研究_沈东生:1.3119425371801974\n",
      "4\n",
      "工程造价指数与工程造价动态管理刍议_孙静:0.969745738492992\n",
      "22\n",
      "基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超:0.8931336505414746\n",
      "20\n",
      "应用型高校金融学课程教学改革研究_邓旭霞:0.8669451233115186\n",
      "24\n",
      "芬兰教育的核心竞争力_高质量的教师队伍_刘蕊:0.5269008031710858\n",
      "41\n",
      "县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应:0.49094762225912963\n",
      "12\n",
      "河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗:0.2576320203286757\n",
      "33\n",
      "耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明:0.162285284084546\n",
      "40\n",
      "[['浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', 'Computer', '机械设计,自动化,制造,计算机技术,发展'], ['电力文本数据挖掘现状及挑战_王慧芳', 'Energy', '文本,缺陷,文本挖掘,电力,数据挖掘'], ['遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', 'Medical', '数据挖掘,数据,医疗,算法,技术'], ['面向调度运行分析的电网数据分析与挖掘_张英华', 'Space', '电网,调度,分析,数据挖掘,指标'], ['数据挖掘技术在风力发电中的应用综述_曾文珺', 'Computer', '数据挖掘,算法,模型,故障诊断,机组'], ['建筑结构设计中的抗震结构设计理念_马玉洁', 'Space', '抗震,结构设计,结构,建筑,建筑物'], ['基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', 'Computer', '聚类,算法,数据挖掘,ik,档案'], ['基于大数据的商业智能在电商数据分析中的应用_钱丹丹', 'Economy', '数据,中药饮片,客户,企业,质心'], ['我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', 'Medical', '互认,医疗,检查,医院,制度'], ['数据挖掘技术在语音识别中的应用_许元洪_郭琼', 'Computer', '语音,样本,算法,说话人识别,降维'], ['基于数据挖掘的电影票房分析_席稼玮', 'Sports', '电影票房,电影,票房,本文,决策树'], ['乡村振兴战略下环巢湖休闲农业发展研究_沈东生', 'Agriculture', '巢湖,休闲,农业,旅游,产品'], ['工程造价指数与工程造价动态管理刍议_孙静', 'Law', '工程造价,管理,造价,工程,建筑工程'], ['基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', 'Computer', '胴体,模型,图像,算法,样本'], ['应用型高校金融学课程教学改革研究_邓旭霞', 'Economy', '金融学,金融,教学,课程,应用型'], ['芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', 'Sports', '教师,教育,芬兰,师范生,教师队伍'], ['县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', 'Medical', '患者,体验,维度,服务,评价'], ['河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', 'Sports', '创业,创新,大学生,教育,高校'], ['耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', 'Agriculture', '贫困,耕地,兰西县,发生率,poverty']]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat May  4 17:15:04 2019\n",
    "\n",
    "@author: Administrator\n",
    "\"\"\"\n",
    "from MyDataFrame import MyDataFrame\n",
    "from GetCatagory import GetCatagory\n",
    "from GetKeywords import ToTFIDF\n",
    "from SearchFiles import BM25\n",
    "import operator\n",
    "import jieba\n",
    "        \n",
    "class GetData(object):\n",
    "    data =[]\n",
    "    def setInitData(self):\n",
    "        #标题\n",
    "        mdf = MyDataFrame()\n",
    "        df = mdf.new_DataFrame()\n",
    "        #类别\n",
    "        gc = GetCatagory()\n",
    "        catagory_list = gc.getAllTextCatagory()\n",
    "        #关键词\n",
    "        tfidf = ToTFIDF()\n",
    "             \n",
    "        for i in range(len(df)):\n",
    "            filename = df.filename[i]\n",
    "            catagory = catagory_list[i]\n",
    "            keywords = tfidf.get_keywords(filename)   #list\n",
    "            keywords_str = ','.join(keywords[:5])\n",
    "            onedata = [filename,catagory,keywords_str]\n",
    "            self.data.append(onedata)\n",
    "            \n",
    "    def getInitData(self):\n",
    "        self.setInitData()\n",
    "        return self.data\n",
    "    \n",
    "    def getCatagoryData(self,catagory):\n",
    "        catagory_data =[]\n",
    "        #print(catagory)\n",
    "        if catagory == 'A_All':\n",
    "            catagory_data = self.data\n",
    "        else:\n",
    "            #print('-------------------')\n",
    "            for i in range(len(self.data)):\n",
    "                #print(self.data[i])\n",
    "                if self.data[i][1] == catagory:\n",
    "                    catagory_data.append(self.data[i])\n",
    "                           \n",
    "        return catagory_data\n",
    "        \n",
    "     \n",
    "    def getSearchFiles(self,str_search):\n",
    "        mdf = MyDataFrame()\n",
    "        df = mdf.new_DataFrame()\n",
    "        df2 = mdf.m_cut(df)\n",
    "        filelist=[]\n",
    "        for i in range(len(df2)):\n",
    "            filelist.append(df2['fenci'][i])\n",
    "        \n",
    "        \n",
    "        s = BM25(filelist)\n",
    "        #print(s.f)\n",
    "        #print(s.idf)\n",
    "        #print(s.simall(['医疗机构', '数据挖掘', '领域', '一带一路', '领域']))\n",
    "        #print(type(s.simall(['医疗机构', '数据挖掘', '领域', '一带一路', '领域'])))\n",
    "        \n",
    "        #对str_search 进行分词去停用词处理\n",
    "        str_search_list = jieba.lcut_for_search(str_search)\n",
    "        \n",
    "        scores = s.simall(str_search_list)\n",
    "        #scores.sort()\n",
    "        #print(scores)\n",
    "        simfile_list = []\n",
    "        for i in range(len(scores)):\n",
    "            simfile_list.append((i,scores[i]))\n",
    "            \n",
    "        simfile_list.sort(key=operator.itemgetter(1),reverse=True)\n",
    "        #print(simfile_list)\n",
    "        \n",
    "        simfiles =[]\n",
    "        gc = GetCatagory()\n",
    "        catagory_list = gc.getAllTextCatagory()\n",
    "        tfidf = ToTFIDF()\n",
    "        \n",
    "        for i in range(len(simfile_list)):\n",
    "            a,b = simfile_list[i]\n",
    "            if b > 0:\n",
    "                #print(df.filename[a] +\":\"+str(b))       \n",
    "                filename = df.filename[a]\n",
    "                catagory = catagory_list[a]\n",
    "                keywords = tfidf.get_keywords(filename)   #list\n",
    "                keywords_str = ','.join(keywords[:5])\n",
    "                simfiles.append([filename,catagory,keywords_str])\n",
    "           \n",
    "        return simfiles      \n",
    "                \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    gd = GetData()\n",
    "    data = gd.getInitData()\n",
    "    #print(data)\n",
    "    \n",
    "    catagory_data = gd.getCatagoryData('Computer')\n",
    "    #print(catagory_data)\n",
    "    str_search = \"数据挖掘与计算机技术\"\n",
    "    simfiles = gd.getSearchFiles(str_search)\n",
    "    print(simfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
