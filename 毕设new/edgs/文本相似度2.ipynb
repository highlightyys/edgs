{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.gensim实现文本相似度----原始词频LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅', '_一带一路_背景下_国际投资_课_省略_路径探析_以广西民族师范学院为例_郑国富', '三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏', '不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹', '乡村振兴战略下环巢湖休闲农业发展研究_沈东生', '二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁', '关于建筑工程管理的影响因素分析与对策探讨_王君霞_战丙利', '关于彰武县做好互换并地后续工作的建议_张凤华', '关于深化河北省农业水价综合改革的对策建议_马素英', '农村非正规金融发展与农村多维贫困_基于面板门槛模型的研究_吴君娴_黄永兴', '医师多点执业对医院人力资源管理的影响_张妍_李吉', '协同创新优化现代高效农业组织结构_王瑜', '县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', '双创背景下大学生农业创业融资问题探析_王涛_白林_齐骥霆', '吉林省农村金融发展状况及对策研究_孙铁柱', '国家重点研发计划_畜禽_专项立项特征研究_姜玮', '地方高校工科专业课程教学模式改革_省略_临沂大学_大气污染控制工程_为例_马宏卿', '基于大数据的商业智能在电商数据分析中的应用_钱丹丹', '基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', '基于数据挖掘的电影票房分析_席稼玮', '基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', '工程教育专业认证下自动化专业实践教学体系的构建_黄宜庆_陆华才', '工程造价指数与工程造价动态管理刍议_孙静', '广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_', '应用型高校金融学课程教学改革研究_邓旭霞', '建筑工程施工管理及创新技术的应用研究_侯帅', '建筑工程施工管理的进度管理与控制_吕萌', '建筑结构设计中的抗震结构设计理念_马玉洁', '建筑门窗用硅烷改性聚醚胶的性能与应用研究_杨苏邯_陈洋庆_陈建军_龙飞_蒋金博_', '我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', '数据挖掘技术在语音识别中的应用_许元洪_郭琼', '数据挖掘技术在风力发电中的应用综述_曾文珺', '智能建筑电气安装工程质量控制要点解析_张凯_张振玉', '河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', '浅析建筑道桥的施工成本把控现状及解决对策_温秀红', '浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', '浅谈洛阳地区窑居建筑通风采光设计策略_周亚豪_赵余光_梁文涛_陈奕甫_杨梦辉', '浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明', '电力文本数据挖掘现状及挑战_王慧芳', '绥化市农业电子商务发展模式研究_余娟_赵艳_孙晓_李冰_张云晖', '耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', '芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', '药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸', '藜麦营养功能与开发利用进展_王启明', '解析装配式建筑工程施工过程中BIM技术的应用_刘志文', '辽宁省特色人才培养模式研究_郭晓林_徐靓', '遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', '面向调度运行分析的电网数据分析与挖掘_张英华', '高校大学生就业指导中的思想政治教育研究_张梦君', '高校油画专业课堂教学改革探究_舒文鑫']\n",
      "Wall time: 12.4 s\n",
      "[(0, 0.99956632)]\n",
      "[(3, 0.99892265)]\n",
      "[(2, 0.99951565)]\n",
      "[(2, 0.99945617)]\n",
      "[(1, 0.041981962), (4, 0.95762557)]\n",
      "[(2, 0.99950188)]\n",
      "[(0, 0.99868953)]\n",
      "[(0, 0.99825466)]\n",
      "[(1, 0.99960816)]\n",
      "[(1, 0.99964839)]\n",
      "[(2, 0.99935359)]\n",
      "[(1, 0.99860251)]\n",
      "[(0, 0.99965918)]\n",
      "[(1, 0.99838841)]\n",
      "[(1, 0.99878258)]\n",
      "[(4, 0.99946094)]\n",
      "[(3, 0.99523139)]\n",
      "[(3, 0.99941289)]\n",
      "[(4, 0.99930608)]\n",
      "[(4, 0.99946511)]\n",
      "[(3, 0.99975252)]\n",
      "[(3, 0.99924618)]\n",
      "[(0, 0.9987697)]\n",
      "[(2, 0.99970686)]\n",
      "[(1, 0.072702132), (3, 0.10607072), (4, 0.82098222)]\n",
      "[(0, 0.48120788), (1, 0.51778799)]\n",
      "[(0, 0.9987843)]\n",
      "[(1, 0.99872857)]\n",
      "[(3, 0.99947971)]\n",
      "[(2, 0.9993431)]\n",
      "[(4, 0.99883956)]\n",
      "[(4, 0.9997527)]\n",
      "[(0, 0.35812563), (3, 0.64098567)]\n",
      "[(1, 0.99967349)]\n",
      "[(0, 0.99924934)]\n",
      "[(1, 0.99859911)]\n",
      "[(3, 0.99928808)]\n",
      "[(1, 0.90131718), (2, 0.09840069)]\n",
      "[(3, 0.99969703)]\n",
      "[(0, 0.98775071), (1, 0.011922621)]\n",
      "[(0, 0.9997921)]\n",
      "[(2, 0.70303607), (3, 0.29653397)]\n",
      "[(0, 0.99822772)]\n",
      "[(2, 0.99979824)]\n",
      "[(0, 0.011422916), (1, 0.98766267)]\n",
      "[(1, 0.99863476)]\n",
      "[(4, 0.99915862)]\n",
      "[(3, 0.99920541)]\n",
      "[(1, 0.020760763), (3, 0.97852045)]\n",
      "[(3, 0.99842083)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.0067917295),\n",
       " (1, 0.0),\n",
       " (2, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (8, 0.0),\n",
       " (9, 0.0),\n",
       " (10, 0.0),\n",
       " (11, 0.0),\n",
       " (12, 0.0),\n",
       " (13, 0.0),\n",
       " (14, 0.0),\n",
       " (15, 0.0),\n",
       " (16, 0.0),\n",
       " (17, 0.0),\n",
       " (18, 0.0),\n",
       " (19, 0.0),\n",
       " (20, 0.0),\n",
       " (21, 0.0),\n",
       " (22, 0.0),\n",
       " (23, 0.0),\n",
       " (24, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0),\n",
       " (32, 0.0),\n",
       " (33, 0.0),\n",
       " (34, 0.0),\n",
       " (35, 0.0),\n",
       " (36, 0.0),\n",
       " (37, 0.0),\n",
       " (38, 0.0),\n",
       " (39, 0.0),\n",
       " (40, 0.0),\n",
       " (41, 0.0),\n",
       " (42, 0.0),\n",
       " (43, 0.0),\n",
       " (44, 0.0),\n",
       " (45, 0.0),\n",
       " (46, 0.0),\n",
       " (47, 0.0),\n",
       " (48, 0.0),\n",
       " (49, 0.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文档预处理\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "filelist=[]\n",
    "for i in range(len(df2)):\n",
    "    filelist.append(df2['fenci'][i])\n",
    "#生成文档对应的字典和bow稀疏矩阵\n",
    "from gensim import corpora, models  \n",
    "\n",
    "dictionary = corpora.Dictionary(filelist)  \n",
    "corpus = [dictionary.doc2bow(text) for text in filelist] # 仍为list in list  \n",
    "\n",
    "#训练LDA并打印训练时间\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "#拟合LDA模型\n",
    "\n",
    "# 列出所消耗的时间备查\n",
    "%time ldamodel = LdaModel(corpus, id2word = dictionary, num_topics = 5, passes = 20) \n",
    "#列出最重要的若干个主题\n",
    "ldamodel.print_topics(num_topics = 5,num_words = 10)\n",
    "\n",
    "\n",
    "#计算各语料的LDA模型值\n",
    "corpus_lda = ldamodel[corpus] # 此处应当使用和模型训练时相同类型的矩阵\n",
    "for doc in corpus_lda:\n",
    "    print(doc)\n",
    "ldamodel.get_topics()#list of list 每个主题中每个词所对应的一个概率矩阵\n",
    "\n",
    "# 检索和文本内容最接近的主题\n",
    " # 检索和0.txt最接近的主题\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "from gensim import similarities\n",
    "\n",
    "simmtx = similarities.MatrixSimilarity(corpus)\n",
    "simmtx#相似矩阵\n",
    "\n",
    "#基于LDA计算余弦相似度\n",
    "simmtx.index[:2]\n",
    "# 使用gensim的LDA拟合结果进行演示\n",
    "\n",
    "query_bow = dictionary.doc2bow(df2['fenci'][1]) # 频数向量\n",
    "lda_vec = ldamodel[query_bow] # 转换为lda模型下的向量\n",
    "sims = simmtx[lda_vec] # 进行矩阵内向量和所提供向量的余弦相似度查询\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅', '_一带一路_背景下_国际投资_课_省略_路径探析_以广西民族师范学院为例_郑国富', '三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏', '不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹', '乡村振兴战略下环巢湖休闲农业发展研究_沈东生', '二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁', '关于建筑工程管理的影响因素分析与对策探讨_王君霞_战丙利', '关于彰武县做好互换并地后续工作的建议_张凤华', '关于深化河北省农业水价综合改革的对策建议_马素英', '农村非正规金融发展与农村多维贫困_基于面板门槛模型的研究_吴君娴_黄永兴', '医师多点执业对医院人力资源管理的影响_张妍_李吉', '协同创新优化现代高效农业组织结构_王瑜', '县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', '双创背景下大学生农业创业融资问题探析_王涛_白林_齐骥霆', '吉林省农村金融发展状况及对策研究_孙铁柱', '国家重点研发计划_畜禽_专项立项特征研究_姜玮', '地方高校工科专业课程教学模式改革_省略_临沂大学_大气污染控制工程_为例_马宏卿', '基于大数据的商业智能在电商数据分析中的应用_钱丹丹', '基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', '基于数据挖掘的电影票房分析_席稼玮', '基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', '工程教育专业认证下自动化专业实践教学体系的构建_黄宜庆_陆华才', '工程造价指数与工程造价动态管理刍议_孙静', '广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_', '应用型高校金融学课程教学改革研究_邓旭霞', '建筑工程施工管理及创新技术的应用研究_侯帅', '建筑工程施工管理的进度管理与控制_吕萌', '建筑结构设计中的抗震结构设计理念_马玉洁', '建筑门窗用硅烷改性聚醚胶的性能与应用研究_杨苏邯_陈洋庆_陈建军_龙飞_蒋金博_', '我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', '数据挖掘技术在语音识别中的应用_许元洪_郭琼', '数据挖掘技术在风力发电中的应用综述_曾文珺', '智能建筑电气安装工程质量控制要点解析_张凯_张振玉', '河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', '浅析建筑道桥的施工成本把控现状及解决对策_温秀红', '浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', '浅谈洛阳地区窑居建筑通风采光设计策略_周亚豪_赵余光_梁文涛_陈奕甫_杨梦辉', '浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明', '电力文本数据挖掘现状及挑战2', '电力文本数据挖掘现状及挑战_王慧芳', '绥化市农业电子商务发展模式研究_余娟_赵艳_孙晓_李冰_张云晖', '耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', '芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', '药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸', '藜麦营养功能与开发利用进展_王启明', '解析装配式建筑工程施工过程中BIM技术的应用_刘志文', '辽宁省特色人才培养模式研究_郭晓林_徐靓', '遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', '面向调度运行分析的电网数据分析与挖掘_张英华', '高校大学生就业指导中的思想政治教育研究_张梦君', '高校油画专业课堂教学改革探究_舒文鑫']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.0067917295),\n",
       " (1, 0.0),\n",
       " (2, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (8, 0.0),\n",
       " (9, 0.0),\n",
       " (10, 0.0),\n",
       " (11, 0.0),\n",
       " (12, 0.0),\n",
       " (13, 0.0),\n",
       " (14, 0.0),\n",
       " (15, 0.0),\n",
       " (16, 0.0),\n",
       " (17, 0.0),\n",
       " (18, 0.0),\n",
       " (19, 0.0),\n",
       " (20, 0.0),\n",
       " (21, 0.0),\n",
       " (22, 0.0),\n",
       " (23, 0.0),\n",
       " (24, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0),\n",
       " (32, 0.0),\n",
       " (33, 0.0),\n",
       " (34, 0.0),\n",
       " (35, 0.0),\n",
       " (36, 0.0),\n",
       " (37, 0.0),\n",
       " (38, 0.0),\n",
       " (39, 0.0),\n",
       " (40, 0.0),\n",
       " (41, 0.0),\n",
       " (42, 0.0),\n",
       " (43, 0.0),\n",
       " (44, 0.0),\n",
       " (45, 0.0),\n",
       " (46, 0.0),\n",
       " (47, 0.0),\n",
       " (48, 0.0),\n",
       " (49, 0.0),\n",
       " (50, 0.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "#2.gensim实现\n",
    "from gensim import similarities\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "filelist=[]\n",
    "for i in range(len(df2)):\n",
    "    filelist.append(df2['fenci'][i])\n",
    "#生成文档对应的字典和bow稀疏矩阵\n",
    "from gensim import corpora, models  \n",
    "\n",
    "dictionary = corpora.Dictionary(filelist) \n",
    "corpus = [dictionary.doc2bow(text) for text in filelist]\n",
    "\n",
    "simmtx = similarities.MatrixSimilarity(corpus)\n",
    "simmtx#相似矩阵\n",
    "\n",
    "#基于LDA计算余弦相似度\n",
    "simmtx.index[:2]\n",
    "\n",
    "ldamodel = LdaModel(corpus, id2word = dictionary, num_topics = 20, passes = 20)#拟合的好，最大值接近1\n",
    "\n",
    "# 使用gensim的LDA拟合结果进行演示\n",
    "query_bow = dictionary.doc2bow(df2['fenci'][4]) # 频数向量\n",
    "\n",
    "lda_vec = ldamodel[query_bow] # 转换为lda模型下的向量\n",
    "sims = simmtx[lda_vec] # 进行矩阵内向量和所提供向量的余弦相似度查询\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009_2016年云南省医疗机构消毒灭菌效果趋势评价_李建云_周晓梅', '_一带一路_背景下_国际投资_课_省略_路径探析_以广西民族师范学院为例_郑国富', '三级医院医疗检查结果互认实施现状及影响因素分析_肖晓华_廖惠_梁恒斌_潘振威_苏', '不同等级医院医疗检查结果互认标准研究_肖晓华_谢欣睿_梁恒斌_廖惠_潘振威_苏茹', '乡村振兴战略下环巢湖休闲农业发展研究_沈东生', '二三级医院影像学检查结果互认现状及影响因素研究_肖晓华_苏茹茹_潘振威_廖惠_梁', '关于建筑工程管理的影响因素分析与对策探讨_王君霞_战丙利', '关于彰武县做好互换并地后续工作的建议_张凤华', '关于深化河北省农业水价综合改革的对策建议_马素英', '农村非正规金融发展与农村多维贫困_基于面板门槛模型的研究_吴君娴_黄永兴', '医师多点执业对医院人力资源管理的影响_张妍_李吉', '协同创新优化现代高效农业组织结构_王瑜', '县级公立医院患者体验的影响因素研究_朱锦_胡丹_陈家应', '双创背景下大学生农业创业融资问题探析_王涛_白林_齐骥霆', '吉林省农村金融发展状况及对策研究_孙铁柱', '国家重点研发计划_畜禽_专项立项特征研究_姜玮', '地方高校工科专业课程教学模式改革_省略_临沂大学_大气污染控制工程_为例_马宏卿', '基于大数据的商业智能在电商数据分析中的应用_钱丹丹', '基于数据挖掘技术的档案馆信息快速分析算法研究_甘璐', '基于数据挖掘的电影票房分析_席稼玮', '基于机器视觉和机器学习技术的鸡胴体质量自动分级方法研究_戚超', '工程教育专业认证下自动化专业实践教学体系的构建_黄宜庆_陆华才', '工程造价指数与工程造价动态管理刍议_孙静', '广西综合医院新生儿病房分级建设和能力建设现状调查_胡琴燕_韦琴_黄晓波_杨少丽_', '应用型高校金融学课程教学改革研究_邓旭霞', '建筑工程施工管理及创新技术的应用研究_侯帅', '建筑工程施工管理的进度管理与控制_吕萌', '建筑结构设计中的抗震结构设计理念_马玉洁', '建筑门窗用硅烷改性聚醚胶的性能与应用研究_杨苏邯_陈洋庆_陈建军_龙飞_蒋金博_', '我国医疗检查结果互认制度实施现状_肖晓华_梁恒斌_谢欣睿_苏茹茹_孙刚', '数据挖掘技术在语音识别中的应用_许元洪_郭琼', '数据挖掘技术在风力发电中的应用综述_曾文珺', '智能建筑电气安装工程质量控制要点解析_张凯_张振玉', '河北省高校大学生创业支持体系优化研究_何腾霄_王丽媛_白欣蕊_冯华_李姗姗', '浅析建筑道桥的施工成本把控现状及解决对策_温秀红', '浅析机械设计制造及其自动化中计算机技术的应用_郑宏栗', '浅谈洛阳地区窑居建筑通风采光设计策略_周亚豪_赵余光_梁文涛_陈奕甫_杨梦辉', '浙江医疗卫生服务领域_最多跑一次_改革政策分析_胡重明', '电力文本数据挖掘现状及挑战_王慧芳', '绥化市农业电子商务发展模式研究_余娟_赵艳_孙晓_李冰_张云晖', '耕地资源富集区县域贫困格局及其影响机制_以黑龙江省兰西县为例_杜国明', '芬兰教育的核心竞争力_高质量的教师队伍_刘蕊', '药品零加成背景下县级公立医院绩效改革困境_刘丽杭_陶飞旸', '藜麦营养功能与开发利用进展_王启明', '解析装配式建筑工程施工过程中BIM技术的应用_刘志文', '辽宁省特色人才培养模式研究_郭晓林_徐靓', '遗传算法的数据挖掘技术在医疗大数据中的应用研究_陈萌', '面向调度运行分析的电网数据分析与挖掘_张英华', '高校大学生就业指导中的思想政治教育研究_张梦君', '高校油画专业课堂教学改革探究_舒文鑫']\n",
      "Wall time: 14.5 s\n",
      "[(0, 0.0163578), (1, 0.015620314), (2, 0.015656369), (3, 0.015662909), (4, 0.93670261)]\n",
      "[(0, 0.013297629), (1, 0.013135372), (2, 0.013248766), (3, 0.01314392), (4, 0.94717431)]\n",
      "[(0, 0.9309454), (1, 0.017256329), (2, 0.017268581), (3, 0.017263284), (4, 0.017266462)]\n",
      "[(0, 0.93624645), (1, 0.015927488), (2, 0.01594089), (3, 0.015936222), (4, 0.015948918)]\n",
      "[(0, 0.91771841), (1, 0.020543825), (2, 0.02064733), (3, 0.020525994), (4, 0.020564422)]\n",
      "[(0, 0.92919701), (1, 0.017692424), (2, 0.01770214), (3, 0.01770144), (4, 0.01770694)]\n",
      "[(0, 0.92201763), (1, 0.019477095), (2, 0.019519987), (3, 0.01947622), (4, 0.019509071)]\n",
      "[(0, 0.015750108), (1, 0.015520301), (2, 0.9377479), (3, 0.015491812), (4, 0.015489863)]\n",
      "[(0, 0.017987372), (1, 0.017566081), (2, 0.017743006), (3, 0.92912287), (4, 0.017580656)]\n",
      "[(0, 0.91444731), (1, 0.021312138), (2, 0.02155209), (3, 0.021293666), (4, 0.021394784)]\n",
      "[(0, 0.39716566), (1, 0.025937617), (2, 0.025997225), (3, 0.026002871), (4, 0.52489662)]\n",
      "[(0, 0.94052362), (1, 0.014864981), (2, 0.014907353), (3, 0.014835712), (4, 0.014868339)]\n",
      "[(0, 0.94764191), (1, 0.013071999), (2, 0.013090046), (3, 0.013080924), (4, 0.013115101)]\n",
      "[(0, 0.018761253), (1, 0.018397326), (2, 0.9259882), (3, 0.018390309), (4, 0.018462954)]\n",
      "[(0, 0.020555204), (1, 0.020249443), (2, 0.91870463), (3, 0.020174719), (4, 0.020315995)]\n",
      "[(0, 0.01729884), (1, 0.016986394), (2, 0.017122125), (3, 0.93155891), (4, 0.017033763)]\n",
      "[(0, 0.013877717), (1, 0.013675419), (2, 0.94497389), (3, 0.013686991), (4, 0.013785972)]\n",
      "[(0, 0.012887508), (1, 0.012679176), (2, 0.012682512), (3, 0.012654749), (4, 0.94909602)]\n",
      "[(0, 0.013056064), (1, 0.012912018), (2, 0.012959304), (3, 0.94803995), (4, 0.013032678)]\n",
      "[(0, 0.019353161), (1, 0.92351919), (2, 0.019004973), (3, 0.018947806), (4, 0.019174844)]\n",
      "[(0, 0.011948648), (1, 0.011872494), (2, 0.011902048), (3, 0.011899193), (4, 0.95237762)]\n",
      "[(0, 0.018562343), (1, 0.018241895), (2, 0.92650914), (3, 0.018293126), (4, 0.018393487)]\n",
      "[(0, 0.88147712), (1, 0.029600985), (2, 0.029669169), (3, 0.029601937), (4, 0.029650804)]\n",
      "[(0, 0.23427157), (1, 0.018102117), (2, 0.018186156), (3, 0.71121317), (4, 0.018226948)]\n",
      "[(0, 0.017784841), (1, 0.017466325), (2, 0.017778605), (3, 0.017470423), (4, 0.9294998)]\n",
      "[(0, 0.93320632), (1, 0.01667127), (2, 0.016739259), (3, 0.016685491), (4, 0.016697694)]\n",
      "[(0, 0.90893775), (1, 0.022756509), (2, 0.022772962), (3, 0.022749335), (4, 0.022783466)]\n",
      "[(0, 0.033872437), (1, 0.87367225), (2, 0.03088451), (3, 0.03073738), (4, 0.030833393)]\n",
      "[(0, 0.91152698), (1, 0.022105929), (2, 0.02212566), (3, 0.022107773), (4, 0.022133658)]\n",
      "[(0, 0.92022598), (1, 0.019924199), (2, 0.019957218), (3, 0.019939648), (4, 0.019952919)]\n",
      "[(0, 0.021423995), (1, 0.021112762), (2, 0.91481996), (3, 0.021230567), (4, 0.021412708)]\n",
      "[(0, 0.010901873), (1, 0.010832828), (2, 0.010866668), (3, 0.010843839), (4, 0.95655477)]\n",
      "[(0, 0.43718466), (1, 0.02464827), (2, 0.024639344), (3, 0.48883319), (4, 0.024694586)]\n",
      "[(0, 0.92156494), (1, 0.019505732), (2, 0.019796859), (3, 0.019520424), (4, 0.019612091)]\n",
      "[(0, 0.89699292), (1, 0.025713176), (2, 0.025782678), (3, 0.025724614), (4, 0.025786594)]\n",
      "[(0, 0.030258695), (1, 0.029836643), (2, 0.88007706), (3, 0.02983194), (4, 0.029995671)]\n",
      "[(0, 0.015392036), (1, 0.015168895), (2, 0.9390862), (3, 0.015164444), (4, 0.015188423)]\n",
      "[(0, 0.96149462)]\n",
      "[(0, 0.92373705), (1, 0.018995635), (2, 0.019044252), (3, 0.019019241), (4, 0.019203885)]\n",
      "[(0, 0.018038806), (1, 0.92967474), (2, 0.017633479), (3, 0.017280743), (4, 0.017372236)]\n",
      "[(0, 0.94424367), (1, 0.013914819), (2, 0.013966898), (3, 0.01394088), (4, 0.013933779)]\n",
      "[(0, 0.018989876), (1, 0.018747862), (2, 0.018945068), (3, 0.018758528), (4, 0.92455864)]\n",
      "[(0, 0.93150461), (1, 0.017106811), (2, 0.017138477), (3, 0.0171236), (4, 0.017126484)]\n",
      "[(2, 0.96812743)]\n",
      "[(0, 0.90470874), (1, 0.023691272), (2, 0.023746561), (3, 0.023861021), (4, 0.023992391)]\n",
      "[(0, 0.017083662), (1, 0.016915696), (2, 0.93211836), (3, 0.016921801), (4, 0.016960517)]\n",
      "[(0, 0.93809927), (1, 0.015424035), (2, 0.015443768), (3, 0.015469135), (4, 0.015563807)]\n",
      "[(0, 0.016188318), (1, 0.01596532), (2, 0.016042441), (3, 0.015973093), (4, 0.93583083)]\n",
      "[(0, 0.90629327), (1, 0.023353554), (2, 0.023521559), (3, 0.023355968), (4, 0.023475641)]\n",
      "[(0, 0.87930757), (1, 0.029987482), (2, 0.030418228), (3, 0.029982252), (4, 0.030304488)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.0082163811),\n",
       " (12, 0.0015909246),\n",
       " (5, 0.00016415544),\n",
       " (47, 0.00016056505),\n",
       " (3, 8.9143694e-05),\n",
       " (1, 0.0),\n",
       " (2, 0.0),\n",
       " (4, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (8, 0.0),\n",
       " (9, 0.0),\n",
       " (10, 0.0),\n",
       " (11, 0.0),\n",
       " (13, 0.0),\n",
       " (14, 0.0),\n",
       " (15, 0.0),\n",
       " (16, 0.0),\n",
       " (17, 0.0),\n",
       " (18, 0.0),\n",
       " (19, 0.0),\n",
       " (20, 0.0),\n",
       " (21, 0.0),\n",
       " (22, 0.0),\n",
       " (23, 0.0),\n",
       " (24, 0.0),\n",
       " (25, 0.0),\n",
       " (26, 0.0),\n",
       " (27, 0.0),\n",
       " (28, 0.0),\n",
       " (29, 0.0),\n",
       " (30, 0.0),\n",
       " (31, 0.0),\n",
       " (32, 0.0),\n",
       " (33, 0.0),\n",
       " (34, 0.0),\n",
       " (35, 0.0),\n",
       " (36, 0.0),\n",
       " (37, 0.0),\n",
       " (38, 0.0),\n",
       " (39, 0.0),\n",
       " (40, 0.0),\n",
       " (41, 0.0),\n",
       " (42, 0.0),\n",
       " (43, 0.0),\n",
       " (44, 0.0),\n",
       " (45, 0.0),\n",
       " (46, 0.0),\n",
       " (48, 0.0),\n",
       " (49, 0.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文档预处理\n",
    "from MyDataFrame import MyDataFrame\n",
    "mdf = MyDataFrame()\n",
    "df = mdf.new_DataFrame()\n",
    "df2 = mdf.m_cut(df)\n",
    "filelist=[]\n",
    "for i in range(len(df2)):\n",
    "    filelist.append(df2['fenci'][i])\n",
    "#生成文档对应的字典和bow稀疏矩阵\n",
    "from gensim import corpora, models  \n",
    "\n",
    "dictionary = corpora.Dictionary(filelist)  \n",
    "corpus = [dictionary.doc2bow(text) for text in filelist] # 仍为list in list  \n",
    "\n",
    "tfidf_model = models.TfidfModel(corpus) # 建立TF-IDF模型  \n",
    "corpus_tfidf = tfidf_model[corpus] # 对所需文档计算TF-IDF结果\n",
    "corpus_tfidf\n",
    "\n",
    "\n",
    "#训练LDA并打印训练时间\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "#拟合LDA模型\n",
    "\n",
    "# 列出所消耗的时间备查\n",
    "%time ldamodel = LdaModel(corpus_tfidf, id2word = dictionary, num_topics = 5, passes = 20) \n",
    "#列出最重要的若干个主题\n",
    "ldamodel.print_topics(num_topics = 5,num_words = 10)\n",
    "\n",
    "\n",
    "#计算各语料的LDA模型值\n",
    "corpus_lda = ldamodel[corpus_tfidf] # 此处应当使用和模型训练时相同类型的矩阵\n",
    "for doc in corpus_lda:\n",
    "    print(doc)\n",
    "ldamodel.get_topics()#list of list 每个主题中每个词所对应的一个概率矩阵\n",
    "\n",
    "# 检索和文本内容最接近的主题\n",
    " # 检索和0.txt最接近的主题\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "from gensim import similarities\n",
    "\n",
    "simmtx = similarities.MatrixSimilarity(corpus)\n",
    "simmtx#相似矩阵\n",
    "\n",
    "#基于LDA计算余弦相似度\n",
    "simmtx.index[:2]\n",
    "# 使用gensim的LDA拟合结果进行演示\n",
    "\n",
    "query_bow = dictionary.doc2bow(df2['fenci'][1]) # 频数向量\n",
    "query_tfidf = tfidf_model[query_bow]\n",
    "\n",
    "lda_vec = ldamodel[query_tfidf] # 转换为lda模型下的向量\n",
    "sims = simmtx[lda_vec] # 进行矩阵内向量和所提供向量的余弦相似度查询\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
